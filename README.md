# ğŸš€ Database ER Diagram Construction using Large Language Models (LLMs)

> Leveraging Large Language Models to automatically generate structured ER diagrams from natural language database specifications.

---

## ğŸ“Œ Project Overview

This project explores how **Large Language Models (LLMs)** such as **Llama3** and **Gemma2** can be used to automatically construct **Entity-Relationship (ER) diagrams** from structured natural language prompts.

The goal is to evaluate:

* How reliably LLMs can translate database requirements into formal schema representations.
* The quality and consistency of model-generated ER diagrams.
* The effectiveness of prompt engineering in structured output generation.

This work demonstrates practical applications of LLMs in:

* Automated database design
* Schema generation
* Structured code generation (Mermaid ER syntax)
* Prompt engineering for deterministic outputs

---

## ğŸ¯ Motivation

Designing ER diagrams is a foundational step in database architecture. Traditionally, this requires:

* Manual analysis of requirements
* Logical entity extraction
* Relationship mapping
* Constraint definition

This project investigates whether LLMs can:

âœ” Extract entities
âœ” Identify attributes
âœ” Infer primary and foreign keys
âœ” Define relationships
âœ” Output machine-readable diagram code

If successful, this approach can reduce design time and improve productivity in early-stage system design.

---

## ğŸ§  Models Used

The following open-source LLMs were evaluated:

* **Llama3**
* **Gemma2**
* Executed locally using **Ollama**

Each model was given the same structured prompt and instructed to output:

* Only Mermaid `erDiagram` syntax
* Strict ordering of entities
* Clearly defined keys and relationships
* No explanations (code-only output constraint)

---

## ğŸ—ï¸ Project Structure

```
Database-ER-diagram-construction-using-LLMs/
â”‚
â”œâ”€â”€ OLLAMA Prompt.txt
â”œâ”€â”€ OLLAMA prompt results (gemma2 + llama3).txt
â”œâ”€â”€ ER diagram.png
â”œâ”€â”€ README_Design_decision.pdf
â””â”€â”€ Multi-LLM prompt result screenshot.pdf
```

### File Descriptions

| File                                          | Description                                                                              |
| --------------------------------------------- | ---------------------------------------------------------------------------------------- |
| `OLLAMA Prompt.txt`                           | Carefully engineered prompt used to instruct the LLM to generate a structured ER diagram |
| `OLLAMA prompt results (gemma2 + llama3).txt` | Raw outputs from both LLMs                                                               |
| `ER diagram.png`                              | Rendered ER diagram generated from model output                                          |
| `README_Design_decision.pdf`                  | Design decisions, assumptions, and reasoning                                             |
| `Multi-LLM prompt result screenshot.pdf`      | Visual comparison of multi-model outputs                                                 |

---

## ğŸ› ï¸ Technical Approach

### 1ï¸âƒ£ Prompt Engineering Strategy

The prompt was designed to:

* Explicitly define required entities
* Specify attribute types
* Define key constraints
* Enforce output format (Mermaid ER syntax only)
* Enforce ordering consistency

This reduced hallucination and improved structural reliability.

---

### 2ï¸âƒ£ Structured Output Enforcement

Models were constrained to produce:

```mermaid
erDiagram
    ENTITY ||--o{ OTHER_ENTITY : relationship
```

This ensured:

* Deterministic formatting
* Easy rendering
* Machine-readable schema representation

---

### 3ï¸âƒ£ Model Evaluation Criteria

Outputs were evaluated on:

| Criteria              | Description                         |
| --------------------- | ----------------------------------- |
| Schema Completeness   | Were all entities included?         |
| Relationship Accuracy | Correct cardinality mapping         |
| Key Integrity         | Proper PK/FK usage                  |
| Format Compliance     | Strict Mermaid syntax adherence     |
| Hallucination Rate    | Extra/incorrect entities introduced |

---

## ğŸ“Š Observations & Insights

### ğŸ”¹ LLM Strengths

* Strong entity extraction
* Accurate identification of relationships
* Good compliance with structured output constraints
* Minimal formatting errors when prompt constraints were strict

### ğŸ”¹ Challenges Observed

* Occasional minor attribute inconsistencies
* Cardinality misinterpretation in edge cases
* Sensitivity to prompt wording

### ğŸ”¹ Key Insight

Prompt engineering significantly improves structured output reliability.
Clear constraints reduce hallucinations and improve deterministic formatting.

---

## ğŸ“· Generated ER Diagram

Below is the final generated ER diagram:

![ER Diagram](ER%20diagram.png)

---

## ğŸ”¬ Why This Project Matters

This project demonstrates practical LLM capabilities in:

* Automated schema generation
* Structured code generation
* Prompt engineering optimization
* Multi-model comparison
* AI-assisted system design

It reflects real-world applications such as:

* AI-powered developer assistants
* Schema prototyping tools
* Automated documentation systems
* Database reverse engineering

---

## ğŸ§© Skills Demonstrated

* Large Language Model experimentation
* Prompt engineering
* Structured generation control
* Schema design principles
* Comparative model evaluation
* AI system validation
* Local LLM deployment using Ollama

---

## ğŸš€ Future Improvements

* Add quantitative evaluation metrics (precision/recall on entity detection)
* Expand comparison to GPT-4 / Claude / Mistral
* Build an automated evaluation pipeline
* Develop a web interface for live schema generation
* Add validation layer to check ER correctness programmatically

---

## ğŸ§ª How to Reproduce

1. Install Ollama:

   ```
   https://ollama.com
   ```

2. Pull models:

   ```
   ollama pull llama3
   ollama pull gemma:2b
   ```

3. Run:

   ```
   ollama run llama3
   ```

4. Paste the prompt from `OLLAMA Prompt.txt`

5. Capture the Mermaid output and render using:

   * Mermaid Live Editor
   * VSCode Mermaid plugin
   * Markdown preview tools

---

## ğŸ“ˆ Potential Extensions

This work can be extended toward:

* AI-powered database design assistants
* Schema-to-SQL generation pipelines
* Natural language to full-stack scaffolding
* ER validation using graph-based analysis
* LLM evaluation benchmarking frameworks

---

## ğŸ‘¨â€ğŸ’» Author

**Atharva Thorat**

Interested in:

* Artificial Intelligence
* Machine Learning
* Large Language Models
* Applied AI Systems
* AI for Software Engineering

---

## â­ If Youâ€™re a Recruiter or Hiring Manager

This project demonstrates:

âœ” Practical LLM experimentation
âœ” Structured output control
âœ” AI system evaluation
âœ” Real-world application mindset
âœ” Independent research initiative

I am actively seeking opportunities in:

* AI Engineering
* Machine Learning Engineering
* LLM Research
* Applied AI Development

Feel free to connect!

